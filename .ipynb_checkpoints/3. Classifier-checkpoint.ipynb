{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_testing = pd.read_csv('../Tbrain_Insurance/testing-set.csv')\n",
    "#df_all = pd.read_csv('../Tbrain_Insurance/df_all.csv')\n",
    "df_all = pd.read_csv('../Tbrain_Insurance/df_policy_claim_unuique.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351273, 699)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351273 entries, 0 to 351272\n",
      "Columns: 704 entries, Policy_Number to 2CSD3meanIO\n",
      "dtypes: float64(557), int64(141), object(6)\n",
      "memory usage: 1.8+ GB\n"
     ]
    }
   ],
   "source": [
    "# replace target: \n",
    "replace_date = {'09/2658','10/2622','02/2611','11/2602', '10/2582', '10/2581', '04/2579', '08/2569', '10/2521',\n",
    " '11/2512', '01/2512', '10/2472','08/2471', '11/2464', '03/2464', '12/2453', '01/2442', '07/2280', '02/2152'}\n",
    "print(len(replace_date))\n",
    "replace_date_set = set(replace_date)\n",
    "print(len(replace_date_set))\n",
    "\n",
    "## convert to datetime formate\n",
    "date_cols = ['DOB_of_Driver','Accident_Date','Accident_Time','ibirth', 'dbirth_new']\n",
    "\n",
    "\n",
    "for input1 in replace_date_set:\n",
    "    df_all[date_cols] = df_all[date_cols].replace(input1, pd.to_datetime('01/2017', format ='%m/%Y'))\n",
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOB_of_Driver</th>\n",
       "      <th>Accident_Date</th>\n",
       "      <th>Accident_Time</th>\n",
       "      <th>ibirth</th>\n",
       "      <th>dbirth_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>1980-11-01</td>\n",
       "      <td>1980-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>1956-11-01</td>\n",
       "      <td>1982-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>1954-03-01</td>\n",
       "      <td>1954-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>1978-09-01</td>\n",
       "      <td>1978-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>1960-10-01</td>\n",
       "      <td>1960-10-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DOB_of_Driver        Accident_Date        Accident_Time      ibirth  \\\n",
       "0  2017-01-01 00:00:00  2017-01-01 00:00:00  2017-01-01 00:00:00  1980-11-01   \n",
       "1  2017-01-01 00:00:00  2017-01-01 00:00:00  2017-01-01 00:00:00  1956-11-01   \n",
       "2  2017-01-01 00:00:00  2017-01-01 00:00:00  2017-01-01 00:00:00  1954-03-01   \n",
       "3  2017-01-01 00:00:00  2017-01-01 00:00:00  2017-01-01 00:00:00  1978-09-01   \n",
       "4  2017-01-01 00:00:00  2017-01-01 00:00:00  2017-01-01 00:00:00  1960-10-01   \n",
       "\n",
       "   dbirth_new  \n",
       "0  1980-11-01  \n",
       "1  1982-03-01  \n",
       "2  1954-03-01  \n",
       "3  1978-09-01  \n",
       "4  1960-10-01  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fill datetime value for date_cols \n",
    "df_all[date_cols] = df_all[date_cols].fillna(pd.to_datetime('01/2017', format ='%m/%Y'))\n",
    "df_all[date_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351273 entries, 0 to 351272\n",
      "Data columns (total 5 columns):\n",
      "DOB_of_Driver    351273 non-null datetime64[ns]\n",
      "Accident_Date    351273 non-null datetime64[ns]\n",
      "Accident_Time    351273 non-null datetime64[ns]\n",
      "ibirth           351273 non-null datetime64[ns]\n",
      "dbirth_new       351273 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](5)\n",
      "memory usage: 13.4 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351273 entries, 0 to 351272\n",
      "Columns: 704 entries, Policy_Number to 2CSD3meanIO\n",
      "dtypes: datetime64[ns](5), float64(557), int64(141), object(1)\n",
      "memory usage: 1.8+ GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "152685742"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert to datetime formate\n",
    "date_cols = ['DOB_of_Driver','Accident_Date','Accident_Time','ibirth', 'dbirth_new']\n",
    "\n",
    "df = df_all\n",
    "\n",
    "date_col=['ibirth', 'dbirth_new']\n",
    "for col in date_col:\n",
    "    df[col] =  pd.to_datetime(df[col], format='%Y-%m-%d', errors='ignore')  #'%Y-%m-%d %H:%M:%S'   #errors='coerce'\n",
    "\n",
    "\n",
    "    \n",
    "date_col=['DOB_of_Driver', 'ibirth', 'dbirth_new']\n",
    "for col in date_col:\n",
    "    df[col] =  pd.to_datetime(df[col], format='%m/%Y', errors='ignore')  #'%Y-%m-%d %H:%M:%S'   #errors='coerce'\n",
    "\n",
    "date_col=['Accident_Date']\n",
    "for col in date_col:\n",
    "    df[col] =  pd.to_datetime(df[col], format='%Y/%m', errors='ignore')  #'%Y-%m-%d %H:%M:%S'   #errors='coerce'\n",
    "\n",
    "date_col=['Accident_Time']\n",
    "for col in date_col:\n",
    "    df[col] =  pd.to_datetime(df[col], format='%H:%M', errors='ignore')  #'%Y-%m-%d %H:%M:%S'   #errors='coerce'\n",
    "\n",
    "df[date_cols].info(verbose= True)\n",
    "df_all = df\n",
    "\n",
    "df.info()\n",
    "df = df.drop(date_cols, axis =1)\n",
    "df_all = df\n",
    "df_all.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351273 entries, 0 to 351272\n",
      "Columns: 699 entries, Policy_Number to 2CSD3meanIO\n",
      "dtypes: float64(557), int64(141), object(1)\n",
      "memory usage: 1.8+ GB\n"
     ]
    }
   ],
   "source": [
    "df_all = df_all.fillna(0)\n",
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nature\n",
    "df1 = df_all[(df_all['fsex_1']==1)|(df_all['fsex_2']==1)]\n",
    "\n",
    "df_train1 = df1[df1['Next_Premium']!=100]\n",
    "print(df_train1.shape)\n",
    "df_test1 = df1[df1['Next_Premium']==100]\n",
    "print(df_test1.shape)\n",
    "print(df_train1.shape[0]+df_test1.shape[0])\n",
    "print(df1.shape[0])\n",
    "\n",
    "# Juridical\n",
    "df2 = df_all[(df_all['fsex_ ']==1)]\n",
    "df2 = df2.drop(['i_age', 'd_age'], axis=1)    ######\n",
    "\n",
    "df_train2 = df2[df2['Next_Premium']!=100]\n",
    "print(df_train2.shape)\n",
    "df_test2 = df2[df2['Next_Premium']==100]\n",
    "print(df_test2.shape)\n",
    "print(df_train2.shape[0]+df_test2.shape[0])\n",
    "print(df2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### Optional \n",
    "# # downsampling\n",
    "# df_train = df_train.sample(10000).reset_index()\n",
    "# df_train = df_train[df_train.columns[1:]]\n",
    "# df_train.head()\n",
    "# # df_test = df_test.sample (1400).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ching/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/ching/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_train1['Next_Premium'] = df_train1.apply(lambda row: 0 if row['Next_Premium']==0 else 1, axis =1)\n",
    "df_train2['Next_Premium'] = df_train2.apply(lambda row: 0 if row['Next_Premium']==0 else 1, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue 78.04070664913384\n",
      "cancelled 21.95929335086616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: Next_Premium, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1=df_train1['Next_Premium']\n",
    "print('continue',df_train1[df_train1['Next_Premium']==1].shape[0]/df_train1.shape[0]*100)\n",
    "print('cancelled',df_train1[df_train1['Next_Premium']==0].shape[0]/df_train1.shape[0]*100)\n",
    "y1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue 78.24170920146153\n",
      "cancelled 21.758290798538475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34     1\n",
       "44     1\n",
       "47     1\n",
       "65     0\n",
       "115    1\n",
       "Name: Next_Premium, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = df_train2['Next_Premium']\n",
    "print('continue',df_train2[df_train2['Next_Premium']==1].shape[0]/df_train2.shape[0]*100)\n",
    "print('cancelled',df_train2[df_train2['Next_Premium']==0].shape[0]/df_train2.shape[0]*100)\n",
    "y2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174910, 698)\n",
      "(174910,)\n",
      "(35853, 696)\n",
      "(35853,)\n"
     ]
    }
   ],
   "source": [
    "train_ID1 = df_train1['Policy_Number']\n",
    "df_train1 = df_train1.drop(['Policy_Number'], axis=1)\n",
    "print(df_train1.shape)\n",
    "print(train_ID1.shape)\n",
    "\n",
    "train_ID2 = df_train2['Policy_Number']\n",
    "df_train2 = df_train2.drop(['Policy_Number'], axis=1)\n",
    "print(df_train2.shape)\n",
    "print(train_ID2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120048, 698)\n",
      "(20462, 696)\n"
     ]
    }
   ],
   "source": [
    "df_test1=df_test1.drop(['Next_Premium'], axis=1)\n",
    "print(df_test1.shape)\n",
    "df_test2=df_test2.drop(['Next_Premium'], axis=1)\n",
    "print(df_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120048, 697)\n",
      "(120048,)\n",
      "(20462, 695)\n",
      "(20462,)\n"
     ]
    }
   ],
   "source": [
    "test_ID1=df_test1['Policy_Number']\n",
    "df_test1=df_test1.drop(['Policy_Number'], axis=1)\n",
    "print(df_test1.shape)\n",
    "print(test_ID1.shape)\n",
    "\n",
    "test_ID2=df_test2['Policy_Number']\n",
    "df_test2=df_test2.drop(['Policy_Number'], axis=1)\n",
    "print(df_test2.shape)\n",
    "print(test_ID2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce Dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1 = df_train1.drop(['Next_Premium'], axis=1)\n",
    "test1 = df_test1\n",
    "y_train1 = y1\n",
    "\n",
    "train2 = df_train2.drop(['Next_Premium'], axis=1)\n",
    "test2 = df_test2\n",
    "y_train2 = y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174910, 697)\n",
      "(120048, 697)\n",
      "(174910,)\n",
      "(35853, 695)\n",
      "(20462, 695)\n",
      "(35853,)\n"
     ]
    }
   ],
   "source": [
    "print(train1.shape)\n",
    "print(test1.shape)\n",
    "print(y1.shape)\n",
    "\n",
    "print(train2.shape)\n",
    "print(test2.shape)\n",
    "print(y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    " \n",
    "# ## standarlization\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# stdsc = StandardScaler()\n",
    "# train_std = stdsc.fit_transform(train)\n",
    "# test_std = stdsc.fit_transform(test)\n",
    " \n",
    "# X_std = train_std\n",
    "\n",
    "#     #求共變異係數矩陣\n",
    "# cov_mat = np.cov(X_std.T)\n",
    "# print(\"共變異係數矩陣.shape=\",cov_mat.shape)\n",
    "\n",
    " \n",
    "# #求共變異係數矩陣 的特徵向量及特徵值\n",
    "# eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)\n",
    "# print(\"特徵向量.shape=\",eigen_vecs.shape)\n",
    "\n",
    " \n",
    "# #計算解釋變異數比率 各特徵值/特徵值總和\n",
    "# tot = sum(eigen_vals)\n",
    "# var_exp = [(i / tot) for i in sorted(eigen_vals, reverse=True)]\n",
    "# cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "# # Make a list of (eigenvalue, eigenvector) tuples\n",
    "# eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vecs[:, i])\n",
    "#                for i in range(len(eigen_vals))]\n",
    "\n",
    "# print(\"特徵值，特徵向量length：\",len(eigen_pairs))\n",
    "# eigen_pairs.sort(key=lambda k: k[0], reverse=True)\n",
    "\n",
    "# #保留兩個最具影響力的特徵向量組成13x2 的投影矩陣W\n",
    "# w = np.hstack((eigen_pairs[0][1][:, np.newaxis],\n",
    "#                eigen_pairs[1][1][:, np.newaxis]))\n",
    "\n",
    "# train_pca = X_std.dot(w)\n",
    "# ###################################\n",
    "\n",
    "# X_std = test_std\n",
    "\n",
    "#     #求共變異係數矩陣\n",
    "# cov_mat = np.cov(X_std.T)\n",
    "# print(\"共變異係數矩陣.shape=\",cov_mat.shape)\n",
    "\n",
    " \n",
    "# #求共變異係數矩陣 的特徵向量及特徵值\n",
    "# eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)\n",
    "# print(\"特徵向量.shape=\",eigen_vecs.shape)\n",
    "\n",
    " \n",
    "# #計算解釋變異數比率 各特徵值/特徵值總和\n",
    "# tot = sum(eigen_vals)\n",
    "# var_exp = [(i / tot) for i in sorted(eigen_vals, reverse=True)]\n",
    "# cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "# # Make a list of (eigenvalue, eigenvector) tuples\n",
    "# eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vecs[:, i])\n",
    "#                for i in range(len(eigen_vals))]\n",
    "\n",
    "# print(\"特徵值，特徵向量length：\",len(eigen_pairs))\n",
    "# eigen_pairs.sort(key=lambda k: k[0], reverse=True)\n",
    "\n",
    "# #保留兩個最具影響力的特徵向量組成13x2 的投影矩陣W\n",
    "# w = np.hstack((eigen_pairs[0][1][:, np.newaxis],\n",
    "#                eigen_pairs[1][1][:, np.newaxis]))\n",
    "\n",
    "# test_pca = X_std.dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train = train_pca\n",
    "# test = test_pca\n",
    "# y_train = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Validation function\n",
    "n_folds = 5\n",
    "\n",
    "def mae_cv1(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train1.values)\n",
    "    mae= (-cross_val_score(model, train1.values, y_train1.values, scoring=\"neg_mean_absolute_error\", cv = kf))\n",
    "    return(mae)\n",
    "\n",
    "def mae_cv2(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train2.values)\n",
    "    mae= (-cross_val_score(model, train2.values, y_train2.values, scoring=\"neg_mean_absolute_error\", cv = kf))\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # LASSO Regression :\n",
    "# # This model may be very sensitive to outliers. So we need to made it more robust on them. For that we use the sklearn's Robustscaler() method on pipeline :\n",
    "# lasso = make_pipeline(RobustScaler(), Lasso(alpha = 2, random_state=1))\n",
    "# print(\"lasso mae: \\n\", mae)\n",
    "# print(\"lasso score: {:.4f} ({:.4f})\\n\".format(mae.mean(), mae.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Elastic Net Regression :\n",
    "# # again made robust to outliers:\n",
    "# #l1_list = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "# ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=2, l1_ratio=1, random_state=3))\n",
    "# mae = mae_cv(ENet)\n",
    "# print(\"ENet mae: \\n\", mae)\n",
    "# print(\"ENet score: {:.4f} ({:.4f})\\n\".format(mae.mean(), mae.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Kernel Ridge Regression :\n",
    "# Kernel_list = ['linear','rbf','sigmoid','poly','laplacian','cosine','chi2']\n",
    "# alpha_list = [0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]\n",
    "\n",
    "# KRR = KernelRidge(alpha = 0.02, kernel = 'cosine', degree = 0) \n",
    "# # mae = mae_cv(KRR)\n",
    "# # print(\"KRR mae: \\n\", mae)\n",
    "# # print(\"KRR score: {:.4f} ({:.4f})\\n\".format(mae.mean(), mae.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # With huber loss that makes it robust to outliers:\n",
    "# GBoost = GradientBoostingRegressor()\n",
    "# # mae = mae_cv(GBoost)\n",
    "# # print(\"GBoost mae: \\n\", mae)\n",
    "# # print(\"GBoost score: {:.4f} ({:.4f})\\n\".format(mae.mean(), mae.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Averaged base models class\n",
    "# class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "#     def __init__(self, models):\n",
    "#         self.models = models\n",
    "        \n",
    "#     # we define clones of the original models to fit the data in\n",
    "#     def fit(self, X, y):\n",
    "#         self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "#         # Train cloned base models\n",
    "#         for model in self.models_:\n",
    "#             model.fit(X, y)\n",
    "\n",
    "#         return self\n",
    "    \n",
    "#     #Now we do the predictions for cloned models and average them\n",
    "#     def predict(self, X):\n",
    "#         predictions = np.column_stack([\n",
    "#             model.predict(X) for model in self.models_\n",
    "#         ])\n",
    "#         return np.mean(predictions, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## mae Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mae = mae_cv(lasso)\n",
    "# mae_lasso = mae \n",
    "# print(\"lasso mae: \\n\", mae)\n",
    "# print(\"lasso score: {:.4f} ({:.4f})\\n\".format(mae.mean(), mae.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mae = mae_cv(ENet)\n",
    "# mae_ENet = mae\n",
    "# print(\"ENet mae: \\n\", mae)\n",
    "# print(\"ENet score: {:.4f} ({:.4f})\\n\".format(mae.mean(), mae.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mae = (mae_cv(KRR))\n",
    "# mae_KRR = mae\n",
    "# print(\"KRR mae: \\n\", mae)\n",
    "# print(\"KRR score: {:.4f} ({:.4f})\\n\".format(mae.mean(), mae.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mae = mae_cv(GBoost)\n",
    "# mae_GBoost = mae\n",
    "# print(\"GBoost mae: \\n\", mae)\n",
    "# print(\"GBoost score: {:.4f} ({:.4f})\\n\".format(mae.mean(), mae.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Averaged base models score\n",
    "# averaged_models = AveragingModels(models = (lasso, ENet, GBoost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mae = mae_cv(averaged_models)\n",
    "# mae_Avg = mae\n",
    "# print(\" Averaged base models: {:.4f} ({:.4f})\\n\".format(mae.mean(), mae.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Meta-Model\n",
    "# #Stacking averaged Models Class:\n",
    "# class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "#     def __init__(self, base_models, meta_model, n_folds=5):\n",
    "#         self.base_models = base_models\n",
    "#         self.meta_model = meta_model\n",
    "#         self.n_folds = n_folds\n",
    "   \n",
    "#     # We again fit the data on clones of the original models\n",
    "#     def fit(self, X, y):\n",
    "#         self.base_models_ = [list() for x in self.base_models]\n",
    "#         self.meta_model_ = clone(self.meta_model)\n",
    "#         kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "#         # Train cloned base models then create out-of-fold predictions\n",
    "#         # that are needed to train the cloned meta-model\n",
    "#         out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "#         for i, model in enumerate(self.base_models):\n",
    "#             for train_index, holdout_index in kfold.split(X, y):\n",
    "#                 instance = clone(model)\n",
    "#                 self.base_models_[i].append(instance)\n",
    "#                 instance.fit(X[train_index], y[train_index])\n",
    "#                 y_pred = instance.predict(X[holdout_index])\n",
    "#                 out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "#         # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "#         self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "#         return self\n",
    "   \n",
    "#     #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "#     #meta-features for the final prediction which is done by the meta-model\n",
    "#     def predict(self, X):\n",
    "#         meta_features = np.column_stack([\n",
    "#             np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "#             for base_models in self.base_models_ ])\n",
    "#         return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mae_1(y1, y_pred1):\n",
    "    return mean_absolute_error(y1,y_pred1)\n",
    "def mae_2(y2, y_pred2):\n",
    "    return mean_absolute_error(y2,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Stacking Averaged models Score\n",
    "\n",
    "# stacked_averaged_models = StackingAveragedModels(base_models = (ENet, lasso, GBoost),  #ENet, lasso, KRR\n",
    "#                                                  meta_model = GBoost) #GBoost\n",
    "\n",
    "# mae = mae_cv(stacked_averaged_models)\n",
    "# mae_stacked_avg = mae\n",
    "# print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(mae.mean(), mae.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# more models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lgb.LGBMClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb mae1: \n",
      " [ 0.1759426   0.18166486  0.19524327  0.2100223   0.17163603]\n",
      "lgb score1: 0.1869 (0.0140)\n",
      "\n",
      "lgb mae2: \n",
      " [ 0.15476854  0.16092595  0.16401674  0.1748954   0.16582985]\n",
      "lgb score2: 0.1641 (0.0066)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LGBM :\n",
    "model_lgb = lgb.LGBMClassifier()\n",
    "mae1 = mae_cv1(model_lgb)\n",
    "mae_lgb1 = mae1\n",
    "print(\"lgb mae1: \\n\", mae1)\n",
    "print(\"lgb score1: {:.4f} ({:.4f})\\n\".format(mae1.mean(), mae1.std()))\n",
    "\n",
    "mae2 = mae_cv2(model_lgb)\n",
    "mae_lgb2 = mae2\n",
    "print(\"lgb mae2: \\n\", mae2)\n",
    "print(\"lgb score2: {:.4f} ({:.4f})\\n\".format(mae2.mean(), mae2.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking1:\n",
      "1. feature 19.: cont_ratiotr (24600.000000)\n",
      "2. feature 18.: V_agetr (14200.000000)\n",
      "3. feature 74.: i_agetr (12600.000000)\n",
      "4. feature 1.: Engine_Displacement_(Cubic_Centimeter)tr (11600.000000)\n",
      "5. feature 75.: d_agetr (11100.000000)\n",
      "6. feature 186.: Insured_Amount3tr (9800.000000)\n",
      "7. feature 183.: Premium_meantr (8700.000000)\n",
      "8. feature 192.: P_R_pctAtr (8200.000000)\n",
      "9. feature 3.: Replacement_cost_of_insured_vehicletr (7900.000000)\n",
      "10. feature 195.: P_R_pctOtr (7400.000000)\n",
      "11. feature 188.: I_P_ratio1tr (6500.000000)\n",
      "12. feature 190.: I_P_ratio3tr (6300.000000)\n",
      "13. feature 184.: Insured_Amount1tr (5500.000000)\n",
      "14. feature 212.: Premium_stdtr (5200.000000)\n",
      "15. feature 112.: Premiumtr (4900.000000)\n",
      "Feature ranking2:\n",
      "1. feature 19.: cont_ratiotr (16600.000000)\n",
      "2. feature 1.: Engine_Displacement_(Cubic_Centimeter)tr (10400.000000)\n",
      "3. feature 184.: Insured_Amount3tr (900.000000)\n",
      "4. feature 18.: V_agetr (11200.000000)\n",
      "5. feature 181.: Premium_meantr (1500.000000)\n",
      "6. feature 15.: Policy_Number_Numtr (8300.000000)\n",
      "7. feature 3.: Replacement_cost_of_insured_vehicletr (4400.000000)\n",
      "8. feature 31.: Num_GroupA_onIIDtr (5500.000000)\n",
      "9. feature 186.: I_P_ratio1tr (8900.000000)\n",
      "10. feature 188.: I_P_ratio3tr (1800.000000)\n",
      "11. feature 189.: I_P_ratioOtr (7900.000000)\n",
      "12. feature 193.: P_R_pctOtr (6600.000000)\n",
      "13. feature 190.: P_R_pctAtr (10800.000000)\n",
      "14. feature 30.: Num_GroupB_onIIDtr (1100.000000)\n",
      "15. feature 110.: Premiumtr (0.000000)\n"
     ]
    }
   ],
   "source": [
    "model = model_lgb  #\n",
    "\n",
    "# Nature\n",
    "model.fit(train1, y_train1)\n",
    "train_pred_lgb1 = model.predict(train1)\n",
    "\n",
    "y_pred_lgb1 = model.predict(test1)  #\n",
    "\n",
    "importances1 = model.feature_importances_\n",
    "# std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "indices1 = np.argsort(importances1)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking1:\")\n",
    "\n",
    "for f in range(15):   # train.shape[1]\n",
    "    print(\"%d. feature %d.: %str (%2f)\" % (f + 1, indices1[f], train1.columns[indices1[f]], importances1[indices1[f]]*100))\n",
    "\n",
    "# Juridical  \n",
    "model.fit(train2, y_train2)\n",
    "train_pred_lgb2 = model.predict(train2)\n",
    "\n",
    "y_pred_lgb2 = model.predict(test2)  #\n",
    "\n",
    "importances2 = model.feature_importances_\n",
    "# std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "indices2 = np.argsort(importances2)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking2:\")\n",
    "\n",
    "for f in range(15):   # train.shape[1]\n",
    "    print(\"%d. feature %d.: %str (%2f)\" % (f + 1, indices2[f], train2.columns[indices2[f]], importances2[indices1[f]]*100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgboost mae1: \n",
      " [ 0.17597119  0.17620491  0.18346578  0.1846664   0.17203625]\n",
      "Xgboost score1: 0.1785 (0.0048)\n",
      "\n",
      "Xgboost mae2: \n",
      " [ 0.15128277  0.15897364  0.1651325   0.17503487  0.1665272 ]\n",
      "Xgboost score2: 0.1634 (0.0079)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost :\n",
    "model_xgb = xgb.XGBClassifier() #n_estimators=200\n",
    "mae1 = mae_cv1(model_xgb)\n",
    "mae_xgb1 = mae1 \n",
    "print(\"Xgboost mae1: \\n\", mae1)\n",
    "print(\"Xgboost score1: {:.4f} ({:.4f})\\n\".format(mae1.mean(), mae1.std()))\n",
    "\n",
    "mae2 = mae_cv2(model_xgb)\n",
    "mae_xgb2 = mae2\n",
    "print(\"Xgboost mae2: \\n\", mae2)\n",
    "print(\"Xgboost score2: {:.4f} ({:.4f})\\n\".format(mae2.mean(), mae2.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking1:\n",
      "1. feature 19.: cont_ratiotr (15.820895)\n",
      "2. feature 18.: V_agetr (6.567165)\n",
      "3. feature 186.: Insured_Amount3tr (6.417911)\n",
      "4. feature 0.: Cancellationtr (4.029851)\n",
      "5. feature 75.: d_agetr (3.731343)\n",
      "6. feature 190.: I_P_ratio3tr (3.432836)\n",
      "7. feature 183.: Premium_meantr (3.134328)\n",
      "Feature ranking2:\n",
      "1. feature 19.: cont_ratiotr (11.363637)\n",
      "2. feature 188.: I_P_ratio3tr (6.666667)\n",
      "3. feature 18.: V_agetr (5.151515)\n",
      "4. feature 192.: P_R_pctCtr (3.636364)\n",
      "5. feature 31.: Num_GroupA_onIIDtr (3.636364)\n",
      "6. feature 1.: Engine_Displacement_(Cubic_Centimeter)tr (3.484849)\n",
      "7. feature 29.: Num_GroupC_onIIDtr (3.181818)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "# Nature\n",
    "\n",
    "model = model_xgb  #\n",
    "\n",
    "model.fit(train1, y_train1)\n",
    "train_pred_xgb1 = model.predict(train1)  #\n",
    "\n",
    "y_pred_xgb1 = model.predict(test1)  #\n",
    "\n",
    "importances1 = model.feature_importances_\n",
    "# std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "indices1 = np.argsort(importances1)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking1:\")\n",
    "\n",
    "for f in range(7):   # train.shape[1]\n",
    "    print(\"%d. feature %d.: %str (%2f)\" % (f + 1, indices1[f], train1.columns[indices1[f]], importances1[indices1[f]]*100))\n",
    "\n",
    "# Juridical\n",
    "\n",
    "model = model_xgb  #\n",
    "\n",
    "model.fit(train2, y_train2)\n",
    "train_pred_xgb2 = model.predict(train2)  #\n",
    "\n",
    "y_pred_xgb2 = model.predict(test2)  #\n",
    "\n",
    "importances2 = model.feature_importances_\n",
    "# std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "indices2 = np.argsort(importances2)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking2:\")\n",
    "\n",
    "for f in range(7):   # train.shape[1]\n",
    "    print(\"%d. feature %d.: %str (%2f)\" % (f + 1, indices2[f], train2.columns[indices2[f]], importances2[indices2[f]]*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # RF :\n",
    "# model_rf = RandomForestRegressor(n_estimators=100)  # default n_estimators = 10\n",
    "# mae1 = mae_cv1(model_rf)\n",
    "# mae_rf1 = mae1\n",
    "# print(\"RandomForest mae1: \\n\", mae1)\n",
    "# print(\"\\nRandomForest score1: {:.4f} ({:.4f})\\n\".format(mae1.mean(), mae1.std()))\n",
    "\n",
    "# mae2 = mae_cv2(model_rf)\n",
    "# mae_rf2 = mae2\n",
    "# print(\"RandomForest mae2: \\n\", mae2)\n",
    "# print(\"\\nRandomForest score2: {:.4f} ({:.4f})\\n\".format(mae2.mean(), mae2.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = model_rf  #\n",
    "\n",
    "# model.fit(train1, y_train1)\n",
    "# train_pred_rf1 = model.predict(train1)  #\n",
    "\n",
    "# y_pred_rf1 = model.predict(test1)  #\n",
    "\n",
    "# importances1 = model.feature_importances_\n",
    "# #std = np.std([tree.feature_importances_ for tree in model_rf.estimators_], axis=0)\n",
    "# indices1 = np.argsort(importances1)[::-1]\n",
    "\n",
    "# # Print the feature ranking\n",
    "# print(\"Feature ranking1:\")\n",
    "\n",
    "# for f in range(7):\n",
    "#     print(\"%d. feature %d.: %str (%2f)\" % (f + 1, indices1[f], train1.columns[indices1[f]], importances1[indices1[f]]*100))\n",
    "\n",
    "\n",
    "# model.fit(train2, y_train2)\n",
    "# train_pred_rf2 = model.predict(train2)  #\n",
    "\n",
    "# y_pred_rf2 = model.predict(test2)  #\n",
    "\n",
    "# importances2 = model.feature_importances_\n",
    "# #std = np.std([tree.feature_importances_ for tree in model_rf.estimators_], axis=0)\n",
    "# indices2 = np.argsort(importances2)[::-1]\n",
    "\n",
    "# # Print the feature ranking\n",
    "# print(\"Feature ranking2:\")\n",
    "\n",
    "# for f in range(7):\n",
    "#     print(\"%d. feature %d.: %str (%2f)\" % (f + 1, indices2[f], train2.columns[indices2[f]], importances2[indices2[f]]*100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mae_rf on train: 801.865598\n",
    "# Feature ranking:\n",
    "# 1. feature 166.: Premiumtr (29.192158)\n",
    "# 2. feature 167.: Premium_Predtr (26.174226)\n",
    "# 3. feature 258.: Premium_Pred_Addtr (8.405166)\n",
    "# 4. feature 72.: Replacement_cost_of_insured_vehicletr (5.817675)\n",
    "# 5. feature 71.: Engine_Displacement_(Cubic_Centimeter)tr (1.952259)\n",
    "# 6. feature 242.: Insured_Amount1_meantr (1.222075)\n",
    "# 7. feature 78.: aassured_ziptr (1.193084)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Final Training and Prediction: \n",
    "# stacked_averaged_models.fit(train.values, y_train.values)\n",
    "# stacked_train_pred = stacked_averaged_models.predict(train.values)\n",
    "# stacked_pred = stacked_averaged_models.predict(test.values)\n",
    "\n",
    "# print(mae_(y_train, stacked_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_pred_lgb1))\n",
    "print(type(y_pred_xgb1))\n",
    "print(type(y_pred_lgb2))\n",
    "print(type(y_pred_xgb2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 0.3\n",
    "x = 0.7\n",
    "r = 1 - l - x\n",
    "# s = 1- l - x - r\n",
    "\n",
    "# ensemble_train = stacked_train_pred * s + train_pred_lgb *l + train_pred_xgb* x + train_pred_rf * r\n",
    "# ensemble_test = stacked_pred * s + y_pred_lgb * l + y_pred_xgb * x + y_pred_rf *r\n",
    "\n",
    "ensemble_train1 =  train_pred_lgb1 *l + train_pred_xgb1* x \n",
    "ensemble_test1 =   y_pred_lgb1 * l + y_pred_xgb1 * x \n",
    "\n",
    "ensemble_train2 =  train_pred_lgb2 *l + train_pred_xgb2* x \n",
    "ensemble_test2 =   y_pred_lgb2 * l + y_pred_xgb2 * x \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE score on train data 1:\n",
      "0.174661826082\n",
      "MAE score on train data 2:\n",
      "0.15431623574\n"
     ]
    }
   ],
   "source": [
    "print('MAE score on train data 1:')  # 1844.5\n",
    "print(mae_1(y_train1, ensemble_train1))\n",
    "\n",
    "print('MAE score on train data 2:')  # 1844.5\n",
    "print(mae_2(y_train2, ensemble_train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## prep submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Final</th>\n",
       "      <th>lgb</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54791</th>\n",
       "      <td>0.916632</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83383</th>\n",
       "      <td>-0.032263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0.852123</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86628</th>\n",
       "      <td>0.899382</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97794</th>\n",
       "      <td>0.877920</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21719</th>\n",
       "      <td>0.906671</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64825</th>\n",
       "      <td>0.897690</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75855</th>\n",
       "      <td>0.844650</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13602</th>\n",
       "      <td>0.850838</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19513</th>\n",
       "      <td>0.839707</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Final  lgb  xgb\n",
       "54791  0.916632    1    1\n",
       "83383 -0.032263    0    0\n",
       "993    0.852123    1    1\n",
       "86628  0.899382    1    1\n",
       "97794  0.877920    1    1\n",
       "21719  0.906671    1    1\n",
       "64825  0.897690    1    1\n",
       "75855  0.844650    1    1\n",
       "13602  0.850838    1    1\n",
       "19513  0.839707    1    1"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred_stacked = pd.DataFrame(stacked_pred)\n",
    "y_pred_lgb1 = pd.DataFrame(y_pred_lgb1)\n",
    "y_pred_xgb1 = pd.DataFrame(y_pred_xgb1)\n",
    "# y_pred_rf1 = pd.DataFrame(y_pred_rf1)\n",
    "\n",
    "y_pred1 = pd.DataFrame(ensemble_test1)\n",
    "\n",
    "all_y1 = pd.concat([y_pred1,y_pred_lgb1, y_pred_xgb1], axis=1)\n",
    "all_y1.columns=['Final', 'lgb','xgb']\n",
    "all_y1.to_csv('Cla_y1.csv')\n",
    "all_y1.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Final</th>\n",
       "      <th>lgb</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>120048.000000</td>\n",
       "      <td>120048.000000</td>\n",
       "      <td>120048.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.808587</td>\n",
       "      <td>0.918333</td>\n",
       "      <td>0.921598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.205049</td>\n",
       "      <td>0.273858</td>\n",
       "      <td>0.268804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.301441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.826124</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.871108</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.901915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.005352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Final            lgb            xgb\n",
       "count  120048.000000  120048.000000  120048.000000\n",
       "mean        0.808587       0.918333       0.921598\n",
       "std         0.205049       0.273858       0.268804\n",
       "min        -0.301441       0.000000       0.000000\n",
       "25%         0.826124       1.000000       1.000000\n",
       "50%         0.871108       1.000000       1.000000\n",
       "75%         0.901915       1.000000       1.000000\n",
       "max         1.005352       1.000000       1.000000"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_y1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Final</th>\n",
       "      <th>lgb</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13874</th>\n",
       "      <td>0.868372</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11623</th>\n",
       "      <td>-0.013823</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16869</th>\n",
       "      <td>0.892704</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18866</th>\n",
       "      <td>0.849875</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6440</th>\n",
       "      <td>0.896326</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4761</th>\n",
       "      <td>0.896449</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11732</th>\n",
       "      <td>0.731526</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13612</th>\n",
       "      <td>0.834855</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17685</th>\n",
       "      <td>0.906346</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>0.893066</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Final  lgb  xgb\n",
       "13874  0.868372    1    1\n",
       "11623 -0.013823    0    0\n",
       "16869  0.892704    1    1\n",
       "18866  0.849875    1    1\n",
       "6440   0.896326    1    1\n",
       "4761   0.896449    1    1\n",
       "11732  0.731526    1    1\n",
       "13612  0.834855    1    1\n",
       "17685  0.906346    1    1\n",
       "6333   0.893066    1    1"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred_stacked = pd.DataFrame(stacked_pred)\n",
    "y_pred_lgb2 = pd.DataFrame(y_pred_lgb2)\n",
    "y_pred_xgb2 = pd.DataFrame(y_pred_xgb2)\n",
    "# y_pred_rf2 = pd.DataFrame(y_pred_rf2)\n",
    "\n",
    "y_pred2 = pd.DataFrame(ensemble_test2)\n",
    "\n",
    "all_y2 = pd.concat([y_pred2,y_pred_lgb2, y_pred_xgb2], axis=1)\n",
    "all_y2.columns=['Final', 'lgb','xgb']\n",
    "all_y2.to_csv('Cla_y2.csv')\n",
    "all_y2.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Final</th>\n",
       "      <th>lgb</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20462.000000</td>\n",
       "      <td>20462.000000</td>\n",
       "      <td>20462.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.814211</td>\n",
       "      <td>0.919558</td>\n",
       "      <td>0.930261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.218937</td>\n",
       "      <td>0.271983</td>\n",
       "      <td>0.254713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.140649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.849356</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.879100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.899558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.997526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Final           lgb           xgb\n",
       "count  20462.000000  20462.000000  20462.000000\n",
       "mean       0.814211      0.919558      0.930261\n",
       "std        0.218937      0.271983      0.254713\n",
       "min       -0.140649      0.000000      0.000000\n",
       "25%        0.849356      1.000000      1.000000\n",
       "50%        0.879100      1.000000      1.000000\n",
       "75%        0.899558      1.000000      1.000000\n",
       "max        0.997526      1.000000      1.000000"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_y2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative prediction1 (#): 1326\n",
      "negative prediction1 (Percent): 1.104558\n",
      "negative prediction2 (#): 419\n",
      "negative prediction2 (Percent): 2.047698\n"
     ]
    }
   ],
   "source": [
    "# Check Negative -> 0 \n",
    "b = all_y1[all_y1['Final']<0].shape[0]\n",
    "a = b/all_y1.shape[0]*100\n",
    "print((\"negative prediction1 (#): %2d\"%b))\n",
    "print(\"negative prediction1 (Percent): %2f\"%a)\n",
    "\n",
    "b = all_y2[all_y2['Final']<0].shape[0]\n",
    "a = b/all_y2.shape[0]*100\n",
    "print((\"negative prediction2 (#): %2d\"%b))\n",
    "print(\"negative prediction2 (Percent): %2f\"%a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# condition1 = all_y['Final']<0\n",
    "# all_y['Final'].loc[condition1] = 0\n",
    "# all_y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140510, 2)\n",
      "(120048,)\n",
      "(120048, 1)\n",
      "(20462,)\n",
      "(20462, 1)\n"
     ]
    }
   ],
   "source": [
    "print(df_testing.shape)\n",
    "print(test_ID1.shape)\n",
    "print(y_pred1.shape)\n",
    "print(test_ID2.shape)\n",
    "print(y_pred2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Policy_Number</th>\n",
       "      <th>Next_Premium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55789b8f86893761c9aa9e7bf17938e737decc68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b6df13a3384528ba6339c52b4fff7c149de68011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e112d926103147bcdcb6dab201b736185a3e2520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa346fa4b1931d1c7a55f8e1bca40b0927dd65ac</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39c4d5daaa791676ec5559c9066d7e8e8dfc51d7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Policy_Number  Next_Premium\n",
       "0  55789b8f86893761c9aa9e7bf17938e737decc68             1\n",
       "1  b6df13a3384528ba6339c52b4fff7c149de68011             1\n",
       "2  e112d926103147bcdcb6dab201b736185a3e2520             0\n",
       "3  aa346fa4b1931d1c7a55f8e1bca40b0927dd65ac             1\n",
       "4  39c4d5daaa791676ec5559c9066d7e8e8dfc51d7             1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(test_ID1).reset_index()\n",
    "# df1['Next_Premium'] = y_pred_lgb1\n",
    "df1['Next_Premium'] = all_y1['xgb']     ##\n",
    "\n",
    "df2 = pd.DataFrame(test_ID2).reset_index()\n",
    "# df2['Next_Premium'] = y_pred_lgb2\n",
    "df2['Next_Premium'] = all_y2['xgb']     ##\n",
    "\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df_cla = df_testing.merge(df, how = 'left', on = 'Policy_Number', suffixes=('_x','_y'))\n",
    "df_cla = df_cla.drop(['index','Next_Premium_x'], axis = 1)\n",
    "df_cla.columns = df_testing.columns\n",
    "\n",
    "df_cla.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140510, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Policy_Number</th>\n",
       "      <th>Next_Premium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55789b8f86893761c9aa9e7bf17938e737decc68</td>\n",
       "      <td>3058.740967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b6df13a3384528ba6339c52b4fff7c149de68011</td>\n",
       "      <td>1551.356567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e112d926103147bcdcb6dab201b736185a3e2520</td>\n",
       "      <td>1649.002808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa346fa4b1931d1c7a55f8e1bca40b0927dd65ac</td>\n",
       "      <td>6763.020020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39c4d5daaa791676ec5559c9066d7e8e8dfc51d7</td>\n",
       "      <td>2588.228760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Policy_Number  Next_Premium\n",
       "0  55789b8f86893761c9aa9e7bf17938e737decc68   3058.740967\n",
       "1  b6df13a3384528ba6339c52b4fff7c149de68011   1551.356567\n",
       "2  e112d926103147bcdcb6dab201b736185a3e2520   1649.002808\n",
       "3  aa346fa4b1931d1c7a55f8e1bca40b0927dd65ac   6763.020020\n",
       "4  39c4d5daaa791676ec5559c9066d7e8e8dfc51d7   2588.228760"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### import regression  df_y: \n",
    "\n",
    "df_y = pd.read_csv('../Tbrain_Insurance/testing-set_xgb.csv')\n",
    "print(df_y.shape)\n",
    "df_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140510, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Policy_Number</th>\n",
       "      <th>Next_Premium_x</th>\n",
       "      <th>Next_Premium_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55789b8f86893761c9aa9e7bf17938e737decc68</td>\n",
       "      <td>1</td>\n",
       "      <td>3058.740967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b6df13a3384528ba6339c52b4fff7c149de68011</td>\n",
       "      <td>1</td>\n",
       "      <td>1551.356567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e112d926103147bcdcb6dab201b736185a3e2520</td>\n",
       "      <td>0</td>\n",
       "      <td>1649.002808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa346fa4b1931d1c7a55f8e1bca40b0927dd65ac</td>\n",
       "      <td>1</td>\n",
       "      <td>6763.020020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39c4d5daaa791676ec5559c9066d7e8e8dfc51d7</td>\n",
       "      <td>1</td>\n",
       "      <td>2588.228760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Policy_Number  Next_Premium_x  Next_Premium_y\n",
       "0  55789b8f86893761c9aa9e7bf17938e737decc68               1     3058.740967\n",
       "1  b6df13a3384528ba6339c52b4fff7c149de68011               1     1551.356567\n",
       "2  e112d926103147bcdcb6dab201b736185a3e2520               0     1649.002808\n",
       "3  aa346fa4b1931d1c7a55f8e1bca40b0927dd65ac               1     6763.020020\n",
       "4  39c4d5daaa791676ec5559c9066d7e8e8dfc51d7               1     2588.228760"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge df_reg & df_y\n",
    "\n",
    "df_final = df_cla.merge(df_y, on = 'Policy_Number')\n",
    "print(df_final.shape)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Policy_Number</th>\n",
       "      <th>Next_Premium_x</th>\n",
       "      <th>Next_Premium_y</th>\n",
       "      <th>Next_Premium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55789b8f86893761c9aa9e7bf17938e737decc68</td>\n",
       "      <td>1</td>\n",
       "      <td>3058.740967</td>\n",
       "      <td>3058.740967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b6df13a3384528ba6339c52b4fff7c149de68011</td>\n",
       "      <td>1</td>\n",
       "      <td>1551.356567</td>\n",
       "      <td>1551.356567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e112d926103147bcdcb6dab201b736185a3e2520</td>\n",
       "      <td>0</td>\n",
       "      <td>1649.002808</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa346fa4b1931d1c7a55f8e1bca40b0927dd65ac</td>\n",
       "      <td>1</td>\n",
       "      <td>6763.020020</td>\n",
       "      <td>6763.020020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39c4d5daaa791676ec5559c9066d7e8e8dfc51d7</td>\n",
       "      <td>1</td>\n",
       "      <td>2588.228760</td>\n",
       "      <td>2588.228760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Policy_Number  Next_Premium_x  Next_Premium_y  \\\n",
       "0  55789b8f86893761c9aa9e7bf17938e737decc68               1     3058.740967   \n",
       "1  b6df13a3384528ba6339c52b4fff7c149de68011               1     1551.356567   \n",
       "2  e112d926103147bcdcb6dab201b736185a3e2520               0     1649.002808   \n",
       "3  aa346fa4b1931d1c7a55f8e1bca40b0927dd65ac               1     6763.020020   \n",
       "4  39c4d5daaa791676ec5559c9066d7e8e8dfc51d7               1     2588.228760   \n",
       "\n",
       "   Next_Premium  \n",
       "0   3058.740967  \n",
       "1   1551.356567  \n",
       "2      0.000000  \n",
       "3   6763.020020  \n",
       "4   2588.228760  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['Next_Premium'] = df_final.apply(lambda row: row['Next_Premium_y'] if row['Next_Premium_x']==1 else 0, axis = 1 )\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Policy_Number</th>\n",
       "      <th>Next_Premium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55789b8f86893761c9aa9e7bf17938e737decc68</td>\n",
       "      <td>3058.740967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b6df13a3384528ba6339c52b4fff7c149de68011</td>\n",
       "      <td>1551.356567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e112d926103147bcdcb6dab201b736185a3e2520</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa346fa4b1931d1c7a55f8e1bca40b0927dd65ac</td>\n",
       "      <td>6763.020020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39c4d5daaa791676ec5559c9066d7e8e8dfc51d7</td>\n",
       "      <td>2588.228760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Policy_Number  Next_Premium\n",
       "0  55789b8f86893761c9aa9e7bf17938e737decc68   3058.740967\n",
       "1  b6df13a3384528ba6339c52b4fff7c149de68011   1551.356567\n",
       "2  e112d926103147bcdcb6dab201b736185a3e2520      0.000000\n",
       "3  aa346fa4b1931d1c7a55f8e1bca40b0927dd65ac   6763.020020\n",
       "4  39c4d5daaa791676ec5559c9066d7e8e8dfc51d7   2588.228760"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = df_final.drop(['Next_Premium_x', 'Next_Premium_y'], axis =1 )\n",
    "df_final.to_csv('testing-set.csv',index = False) \n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Next_Premium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>140510.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4420.648478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4911.002596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2117.625122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3029.080933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4910.342773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>141590.484375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Next_Premium\n",
       "count  140510.000000\n",
       "mean     4420.648478\n",
       "std      4911.002596\n",
       "min         0.000000\n",
       "25%      2117.625122\n",
       "50%      3029.080933\n",
       "75%      4910.342773\n",
       "max    141590.484375"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
