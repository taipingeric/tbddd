{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_policy = pd.read_csv('policy_claim/policy_0702.csv')\n",
    "df_claim = pd.read_csv('policy_claim/claim_0702.csv')\n",
    "df_training = pd.read_csv('training-set.csv')\n",
    "df_testing = pd.read_csv('testing-set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Read Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_policy.shape) # 41 items  (1747942, 41)\n",
    "print('unique:',df_policy['Policy_Number'].nunique()) #351273 unique Policy Number\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_policy.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_policy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### examine Drivers\n",
    "driver = df_policy[['ibirth' , 'dbirth']]\n",
    "print(driver.shape[0])\n",
    "driver.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition1 = driver['ibirth'].isnull()    # 18.2 %\n",
    "condition2 = driver['dbirth'].isnull()    # 14.8 %\n",
    "\n",
    "condition3 = driver['ibirth'].notnull()   \n",
    "condition4 = driver['dbirth'].notnull()   \n",
    "\n",
    "\n",
    "driver_0N= driver[condition3&condition4]  # both have values  (81.5%)\n",
    "driver_1N= driver[condition1^condition2]  # missing one (3.9%)\n",
    "driver_2N= driver[condition1|condition2]  # missing both (18.4%)\n",
    "\n",
    "print(driver_0N.shape[0]/driver.shape[0])\n",
    "print(driver_1N.shape[0]/driver.shape[0]) \n",
    "print(driver_2N.shape[0]/driver.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check indiff. in 0N\n",
    "\n",
    "indiff = driver_0N[driver_0N['ibirth']!=driver_0N['dbirth']]\n",
    "print(indiff.shape[0])\n",
    "indiff.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dbirth has some weird date\n",
    "### check non-null data & sort\n",
    "print(driver['dbirth'].notnull().sum())\n",
    "import datetime\n",
    "a = df_policy[driver['dbirth'].notnull()]['dbirth']\n",
    "b = sorted(a, key=lambda x: datetime.datetime.strptime(x, '%m/%Y'), reverse = True)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_date = {\n",
    "    '09/2658',\n",
    " '09/2658',\n",
    " '09/2658',\n",
    " '09/2658',\n",
    " '10/2622',\n",
    " '10/2622',\n",
    " '10/2622',\n",
    " '10/2622',\n",
    " '02/2611',\n",
    " '02/2611',\n",
    " '02/2611',\n",
    " '02/2611',\n",
    " '02/2611',\n",
    " '02/2611',\n",
    " '11/2602',\n",
    " '11/2602',\n",
    " '11/2602',\n",
    " '11/2602',\n",
    " '11/2602',\n",
    " '11/2602',\n",
    " '11/2602',\n",
    " '11/2602',\n",
    " '10/2582',\n",
    " '10/2582',\n",
    " '10/2582',\n",
    " '10/2582',\n",
    " '10/2581',\n",
    " '10/2581',\n",
    " '04/2579',\n",
    " '04/2579',\n",
    " '04/2579',\n",
    " '04/2579',\n",
    " '04/2579',\n",
    " '04/2579',\n",
    " '04/2579',\n",
    " '04/2579',\n",
    " '04/2579',\n",
    " '08/2569',\n",
    " '08/2569',\n",
    " '08/2569',\n",
    " '08/2569',\n",
    " '08/2569',\n",
    " '10/2521',\n",
    " '11/2512',\n",
    " '11/2512',\n",
    " '11/2512',\n",
    " '11/2512',\n",
    " '11/2512',\n",
    " '01/2512',\n",
    " '01/2512',\n",
    " '01/2512',\n",
    " '01/2512',\n",
    " '01/2512',\n",
    " '10/2472',\n",
    " '10/2472',\n",
    " '08/2471',\n",
    " '08/2471',\n",
    " '08/2471',\n",
    " '08/2471',\n",
    " '08/2471',\n",
    " '11/2464',\n",
    " '11/2464',\n",
    " '11/2464',\n",
    " '03/2464',\n",
    " '03/2464',\n",
    " '12/2453',\n",
    " '12/2453',\n",
    " '12/2453',\n",
    " '12/2453',\n",
    " '01/2442',\n",
    " '01/2442',\n",
    " '01/2442',\n",
    " '01/2442',\n",
    " '01/2442',\n",
    " '01/2442',\n",
    " '07/2280',\n",
    " '07/2280',\n",
    " '07/2280',\n",
    " '07/2280',\n",
    " '07/2280',\n",
    " '07/2280',\n",
    " '07/2280',\n",
    " '07/2280',\n",
    " '02/2152',\n",
    " '02/2152',\n",
    " '02/2152',\n",
    " '02/2152',\n",
    " '02/2152',\n",
    " '02/2152',\n",
    " '02/2152',\n",
    " '02/2152',\n",
    " '02/2152'}\n",
    "len(replace_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_date_set = set(replace_date)\n",
    "len(replace_date_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_switch = df_policy.apply(lambda row: True if row['dbirth'] in replace_date_set else False, axis = 1)\n",
    "df_policy_selected = df_policy[date_switch]\n",
    "print(df_policy_selected.shape[0])\n",
    "df_policy_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_idx = df_policy_selected.index.values\n",
    "selected_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_policy_selected_date = df_policy[['ibirth', 'dbirth','fassured']].loc[df_policy_selected.index]\n",
    "# \"1:國內自然人 2:國內法人 3:國外自然人 4:國外法人 5:自然人ID有誤 6:法人ID有誤\"\n",
    "df1 = df_policy_selected_date[df_policy_selected_date['fassured']==1]\n",
    "df2 = df_policy_selected_date[df_policy_selected_date['fassured']==2]\n",
    "print(df1.shape[0])\n",
    "print(df2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head() ## replace as NaN  (as ibirth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head() ## replace as ibirth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_policy['ID']=df_policy.index   # create ID column for ref.\n",
    "df_policy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### replace weird date as ibirth\n",
    "df_policy['dbirth_new'] = df_policy.apply(lambda row: row['ibirth'] if row['ID'] in selected_idx \n",
    "                                          else row['dbirth'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_policy[['ibirth', 'dbirth', 'fassured','dbirth_new']].loc[selected_idx].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_policy['dbirth'] = df_policy['dbirth_new']\n",
    "df_policy = df_policy.drop(['dbirth_new','ID'], axis =1)\n",
    "df_policy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_policy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_claim.shape)  # 20 items\n",
    "print('unique:',df_claim['Policy_Number'].nunique()) #35895 unique Policy Number\n",
    "pd.set_option('display.max_columns', None)  ## show all columns\n",
    "df_claim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_claim.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_training.shape)\n",
    "print('unique:',df_training['Policy_Number'].nunique()) #210763 unique Policy Number\n",
    "df_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training[df_training['Next_Premium']==100]  # if Next_Premium = 100 -> testing_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_testing.shape)\n",
    "print('unique:',df_testing['Policy_Number'].nunique()) #140510 unique Policy Number\n",
    "df_testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df_training['Policy_Number'].nunique()/df_policy['Policy_Number'].nunique()*100\n",
    "b=df_testing['Policy_Number'].nunique()/df_policy['Policy_Number'].nunique()*100\n",
    "print('training set (pct)  %f '%a)\n",
    "print('testing set (pct)  %f '%b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Combine policy & claim & training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all= df_policy.merge(df_claim, on=df_policy.columns[0], how='left', suffixes=('','_Claim'))\n",
    "print(df_all.columns)\n",
    "print(df_all.shape)   # 60 items (overlap on Policy_Number only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all= df_all.merge(df_training, on=df_policy.columns[0], how='left')\n",
    "df_all= df_all.merge(df_testing, on=df_policy.columns[0], how='left')\n",
    "df_all['Next_Premium'] = df_all.apply(\n",
    "    lambda row: row['Next_Premium_y'] if row['Next_Premium_y']==100 else row['Next_Premium_x'], axis = 1)\n",
    "df_all=df_all.drop(['Next_Premium_x','Next_Premium_y'], axis =1)\n",
    "print(df_all.shape) \n",
    "print(df_all.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 check missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % percentage\n",
    "df_all.isnull().sum()/df_all.shape[0]*100   # about 22.7 declaire claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### df_all.nunique()\n",
    "\n",
    "# '''\n",
    "# Policy_Number                                 351273  Encode\n",
    "# Insured's_ID                                  299999  Encode\n",
    "# Prior_Policy_Number                           281678  Encode\n",
    "# Cancellation                                       2  Dummy\n",
    "# Vehicle_identifier                            347882  Encode\n",
    "# Vehicle_Make_and_Model1                          136  Encode (too many...)\n",
    "# Vehicle_Make_and_Model2                         8112  Encode\n",
    "# Manafactured_Year_and_Month                       49  Datetime\n",
    "# Engine_Displacement_(Cubic_Centimeter)           768  no Change\n",
    "# Imported_or_Domestic_Car                          10  Dummy\n",
    "# Coding_of_Vehicle_Branding_&_Type               7405  Encode\n",
    "# qpt                                               19  Dummy\n",
    "# fpt                                                1  Dummy\n",
    "# Main_Insurance_Coverage_Group                      3  Dummy\n",
    "# Insurance_Coverage                                60  Dummy\n",
    "# Insured_Amount1                                  111  no Change\n",
    "# Insured_Amount2                                   89  no Change\n",
    "# Insured_Amount3                                 3071  no Change\n",
    "# Coverage_Deductible_if_applied                    53  no Change\n",
    "# Premium                                        18238  no Change\n",
    "# Replacement_cost_of_insured_vehicle             2947  no Change\n",
    "# Distribution_Channel                             875  Encode (too many...)\n",
    "# Multiple_Products_with_TmNewa_(Yes_or_No?)       179  no Change (dummy??)\n",
    "# lia_class                                         21  no Change (dummy??)\n",
    "# plia_acc                                          21  no Change (dummy??)\n",
    "# pdmg_acc                                          13  no Change (dummy??)\n",
    "# fassured                                           4  Dummy\n",
    "# ibirth                                           918  Datetime\n",
    "# fsex                                               4  Dummy\n",
    "# fmarriage                                          4  Dummy \n",
    "# aassured_zip                                    1722  Encode (too many...)                                                                       ...  \n",
    "# iply_area                                         22  Dummy\n",
    "# dbirth                                           945  Datetime\n",
    "# fequipment1                                        2  Dummy\n",
    "# fequipment2                                        2  Dummy\n",
    "# fequipment3                                        2  Dummy\n",
    "# fequipment4                                        1  Dummy\n",
    "# fequipment5                                        2  Dummy\n",
    "# fequipment6                                        1  Dummy\n",
    "# fequipment9                                        2  Dummy \n",
    "# nequipment9                                        6  Dummy\n",
    "# ============ Claim  ========\n",
    "# Claim_Number                                   41137  Encode\n",
    "# Nature_of_the_claim                                2  Dummy\n",
    "# Driver's_Gender                                    2  Dummy\n",
    "# Driver's_Relationship_with_Insured                 7  Dummy\n",
    "# DOB_of_Driver                                    799  Datetime\n",
    "# Marital_Status_of_Driver                           2  Dummy\n",
    "# Accident_Date                                     25  Datetime\n",
    "# Cause_of_Loss                                     17  Dummy\n",
    "# Paid_Loss_Amount                               17229  no Change \n",
    "# paid_Expenses_Amount                             799  no Change\n",
    "# Salvage_or_Subrogation?                         2056  no Change\n",
    "# Coverage                                          48  Encode (same as Insurance_Coverage!)\n",
    "# Vehicle_identifier_Claim                       35714  Encode (same as Vehicle_identifier if applicable!)\n",
    "# At_Fault?                                         23  no Change (dummy??)\n",
    "# Claim_Status_(close,_open,_reopen_etc)             2  Dummy\n",
    "# Deductible                                        67  no Change \n",
    "# Accident_area                                     22  Dummy  (same as aassured_zip?)\n",
    "# number_of_claimants                               14  no Change (dummy??)\n",
    "# Accident_Time                                     39  DateTime\n",
    "# Next_Premium                                   22817  no Change\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill na as 0 (Check explaination document, those 0 doesn't mean anything)\n",
    "\n",
    "df= df_all\n",
    "cols = ['Prior_Policy_Number','Vehicle_identifier','fsex','fmarriage','Claim_Number','Nature_of_the_claim','Policy_Number',\n",
    "        \"Driver's_Gender\",\"Driver's_Relationship_with_Insured\",'Marital_Status_of_Driver',\n",
    "        'Cause_of_Loss','number_of_claimants']\n",
    "for col in cols:\n",
    "    df[col]=df[col].fillna(0)\n",
    "    print(col, df[col].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill na as -1 ( becasue 0 means something else)\n",
    "\n",
    "df= df_all\n",
    "cols = ['Paid_Loss_Amount','paid_Expenses_Amount','Salvage_or_Subrogation?', 'At_Fault?', \n",
    "        'Claim_Status_(close,_open,_reopen_etc)', 'Deductible']\n",
    "for col in cols:\n",
    "    df[col]=df[col].fillna(-1)\n",
    "    print(col, df[col].isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Verify and drop \n",
    "df = df_all\n",
    "### verify if 'Vehicle_identifier' = 'Vehicle_identifier_Claim'  (YES)\n",
    "df_temp=df[['Policy_Number','Vehicle_identifier','Vehicle_identifier_Claim']]\n",
    "df_temp2 = df_temp[df_temp['Vehicle_identifier_Claim'].notnull()] \n",
    "print(df_temp2.shape)\n",
    "df_temp2[df_temp2['Vehicle_identifier']==df_temp2['Vehicle_identifier_Claim']]\n",
    "print(df_temp2.shape)     \n",
    "\n",
    "### verify if 'Insurance_Coverage'=='Coverage'    (YES)\n",
    "df_temp=df[['Policy_Number','Insurance_Coverage','Coverage']]\n",
    "df_temp2 = df_temp[df_temp['Coverage'].notnull()] \n",
    "print(df_temp2.shape)\n",
    "df_temp2.head()\n",
    "df_temp2[df_temp2['Insurance_Coverage']==df_temp2['Coverage']]\n",
    "print(df_temp2.shape)  # 'Insurance_Coverage'=='Coverage' if there is value\n",
    "\n",
    "### verify if 'Accident_area'=='iply_area'      (YES)\n",
    "df_temp=df[['Policy_Number','Accident_area','iply_area']]\n",
    "df_temp2 = df_temp[df_temp['Accident_area'].notnull()] \n",
    "print(df_temp2.shape)\n",
    "df_temp2.head()\n",
    "df_temp2[df_temp2['iply_area']==df_temp2['Accident_area']]\n",
    "print(df_temp2.shape)  # 'Accident_area'=='iply_area'' if there is value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop 'Coverage' & 'Vehicle_identifier_Claim' & 'Accident_area\n",
    "df= df_all\n",
    "df = df.drop(['Coverage','Vehicle_identifier_Claim','Accident_area'], axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### fill NaN as (today)\n",
    "\n",
    "# df= df_all\n",
    "# cols = ['ibirth','dbirth','DOB_of_Driver','Accident_Date','Accident_Time']\n",
    "# for col in cols:\n",
    "#     df[col]=df[col].fillna(0)\n",
    "#     print(col, df[col].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_all.isnull().sum()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_all\n",
    "df[df.columns[41:]].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Label Encoder: convert anon id to No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  ## show all columns\n",
    "print(df_all.shape)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "encoded columns:\n",
    "\n",
    "Policy_Number\t保單號碼\n",
    "Insured's_ID\t被保險人代號(替代值)\n",
    "Prior_Policy_Number\t前保單號\n",
    "Vehicle_identifier\t車牌號碼                               ## same as vehicle_identifier\n",
    "Vehicle_Make_and_Model1\t廠牌名稱一                   \n",
    "Vehicle_Make_and_Model2\t廠牌名稱二\n",
    "Coding_of_Vehicle_Branding_&_Type\t廠牌車型代號\n",
    "Distribution_Channel\t主通路代號\n",
    "aassured_zip\t郵遞區號                            \n",
    "Claim_Number\t賠案號碼\n",
    "Vehicle_identifier_Claim\t車牌                           ## same as vehicle_identifier (already drop)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_all\n",
    "\n",
    "## do not include:  Vehicle_identifier_Claim\t車牌  (map to Vehicle_identifier)\n",
    "cols = ('Policy_Number',\"Insured's_ID\",'Prior_Policy_Number','Vehicle_identifier', 'Vehicle_Make_and_Model1',\n",
    "       'Vehicle_Make_and_Model2','Coding_of_Vehicle_Branding_&_Type','Distribution_Channel','aassured_zip',\n",
    "        'Distribution_Channel','aassured_zip','Claim_Number')\n",
    "\n",
    "\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(df[c].values)) \n",
    "    df[c] = lbl.transform(list(df[c].values))\n",
    "\n",
    "# shape        \n",
    "print('Shape of data: {}'.format(df.shape))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Already dropped\n",
    "### encode 'Vehicle_identifier_Claim' (NaN: NaN, not NaN: 'Vehicle_identifier' )\n",
    "# df = df_all\n",
    "# condition1 = df['Vehicle_identifier_Claim'].isnull()\n",
    "# condition2 = df['Vehicle_identifier_Claim'].notnull()\n",
    "\n",
    "# df['Vehicle_identifier_Claim'][condition1]=df['Vehicle_identifier_Claim']\n",
    "# df['Vehicle_identifier_Claim'][condition2]=df['Vehicle_identifier']\n",
    "\n",
    "#df[['Policy_Number','Vehicle_identifier','Vehicle_identifier_Claim']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Get dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "dummy columns:\n",
    "\n",
    "Cancellation                   非繼承自前保單\t類別\tY: 是 、空白: 否(N)\n",
    "Imported_or_Domestic_Car       車系代號\t類別\t參照：車系代號Sheet\n",
    "qpt                            乘載數量\t數值\n",
    "fpt                            乘載單位\t類別\tP:載客 T:噸\n",
    "Main_Insurance_Coverage_Group  險種分類\t類別\t參照:險種分類及自負額說明Sheet\n",
    "Insurance_Coverage    ####     險種代碼\t類別\t參照:險種分類及自負額說明Sheet\n",
    "fassured                       被保險人性質\t類別\t\"1:國內自然人 2:國內法人 3:國外自然人 4:國外法人 5:自然人ID有誤 6:法人ID有誤\"\n",
    "fsex                           性別\t類別\t1:男 2:女 空白:法人(0)\n",
    "fmarriage                      婚姻狀況\t類別\t1:已婚 2:未婚\n",
    "iply_area             ####     承保地區代號(分公司)\t類別\n",
    "fequipment1                    配備-音響註記\t類別\t1:是 0:否\n",
    "fequipment2                    配備-車箱註記\t類別\t1:是 0:否\n",
    "fequipment3                    配備-冷凍機組註記\t類別\t1:是 0:否\n",
    "fequipment4                    配備-車框、車斗註記\t類別\t1:是 0:否\n",
    "fequipment5                    配備-昇降系統註記\t類別\t1:是 0:否\n",
    "fequipment6                    配備-電動車電池註記\t類別\t1:是 0:否\n",
    "fequipment9                    配備-其他\t類別\t1:是 0:否\n",
    "nequipment9                    配備-其他說明\t類別\t1:是 0:否\n",
    "Nature_of_the_claim            賠案性質\t類別\t1.賠付 2.追償\n",
    "Driver's_Gender                肇事駕駛性別\t類別\t1:男 2:女 空白:法人\n",
    "Driver's_Relationship_with_Insured 與被保險人關係\t類別\t\"1:被保險人本人 2:被保險人親友 3:被保險人員工 4:租用被保險車輛 5:其他, 6:配偶, 7:子女\"\n",
    "Marital_Status_of_Driver       肇事駕駛婚姻\t類別\t1:已婚 2:未婚\n",
    "Cause_of_Loss                  出險原因\t類別\n",
    "Coverage             ###       險種代號\t類別  same as insurance_coverage (Already Dropped)\n",
    "Accident_area        ####      出險地區\t類別  same as iply (AlreadyDrop)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Label cancellation from {'Y', ' '}-> {'Y', 'N'} get dummy later\n",
    "df= df_all\n",
    "print(set(df['Cancellation']))\n",
    "input1 = ' '\n",
    "replace1 = 'N'\n",
    "df['Cancellation']=df['Cancellation'].replace(input1, replace1) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Getting dummy categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df_all\n",
    "segment=['Cancellation','Imported_or_Domestic_Car','qpt','fpt','Main_Insurance_Coverage_Group','Insurance_Coverage',\n",
    "         'fassured', 'fsex','fmarriage','iply_area', 'fequipment1','fequipment2','fequipment3','fequipment4',\n",
    "         'fequipment5','fequipment6','fequipment9','nequipment9','Nature_of_the_claim',\"Driver's_Gender\",\n",
    "         \"Driver's_Relationship_with_Insured\", 'Marital_Status_of_Driver', 'Cause_of_Loss']\n",
    "df_dummy = pd.get_dummies(df, columns=segment)\n",
    "print(df_dummy.shape)\n",
    "df_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 convert object (date) to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## check date format\n",
    "date_cols=['ibirth','dbirth','DOB_of_Driver','Accident_Date','Accident_Time']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy[date_cols].info()\n",
    "\"\"\"\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "Int64Index: 1988927 entries, 0 to 1988926\n",
    "Data columns (total 5 columns):\n",
    "ibirth           object\n",
    "dbirth           object               # object... (selected index repalce with ibirth)\n",
    "DOB_of_Driver    object\n",
    "Accident_Date    object\n",
    "Accident_Time    object\n",
    "dtypes: datetime64[ns](4), object(1)\n",
    "memory usage: 91.0+ MB\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy[date_cols].sample(10)  ## 77% missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_dummy['Accident_Time'][1000000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fill NaN as (2020)\n",
    "df= df_dummy\n",
    "\n",
    "cols = ['Accident_Time']\n",
    "for col in cols:\n",
    "    print(df[col].isnull().sum())\n",
    "    df[col]=df[col].fillna(str('00:00'))\n",
    "    print(col, df[col].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['Accident_Time'][1])\n",
    "df['Accident_Time'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df['Accident_Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fill NaN as (2020)\n",
    "\n",
    "cols = ['ibirth','dbirth','DOB_of_Driver']\n",
    "\n",
    "for col in cols:\n",
    "    print(df[col].isnull().sum())\n",
    "    df[col]=df[col].fillna('09/2018')\n",
    "    print(col, df[col].isnull().sum())\n",
    "\n",
    "cols = ['Accident_Date']\n",
    "for col in cols:\n",
    "    print(df[col].isnull().sum())\n",
    "    df[col]=df[col].fillna('2018/09')\n",
    "    print(col, df[col].isnull().sum())\n",
    "\n",
    "df.isnull().sum().sum()    \n",
    "df_dummy= df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy[date_cols].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df= df_dummy\n",
    "\n",
    "date_col={'ibirth','dbirth','DOB_of_Driver'}\n",
    "for col in date_col:\n",
    "    df[col] =  pd.to_datetime(df[col], format='%m/%Y', errors='ignore')  #'%Y-%m-%d %H:%M:%S'   #errors='coerce'\n",
    "\n",
    "date_col={'Accident_Date'}\n",
    "for col in date_col:\n",
    "    df[col] =  pd.to_datetime(df[col], format='%Y/%m',errors='ignore')  #'%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "date_col={'Accident_Time'}\n",
    "for col in date_col:\n",
    "    df[col] =  pd.to_datetime(df[col], format='%H:%M',errors='ignore') #'%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "df_dummy_date = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy_date[['ibirth', 'dbirth' ,'DOB_of_Driver', 'Accident_Date', 'Accident_Time']].info(verbose= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 Extract Features from datetime data then drop datetime64 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy_date[['ibirth', 'dbirth' ,'DOB_of_Driver', 'Accident_Date', 'Accident_Time']].loc[932405]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy_date[['ibirth', 'dbirth' ,'DOB_of_Driver', 'Accident_Date', 'Accident_Time']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Today\n",
    "today = datetime.date.today()\n",
    "daysdiff = today-df_dummy_date['ibirth']\n",
    "components = daysdiff.dt.components #  https://stackoverflow.com/questions/18215317/extracting-days-from-a-numpy-timedelta64-value\n",
    "components.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = components.days/365\n",
    "df_dummy_date['iYearsOld'] = years\n",
    "df_dummy_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.date.today()\n",
    "daysdiff = today-df_dummy_date['dbirth']\n",
    "components = daysdiff.dt.components #  https://stackoverflow.com/questions/18215317/extracting-days-from-a-numpy-timedelta64-value\n",
    "components.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = components.days/365\n",
    "df_dummy_date['dYearsOld'] = years\n",
    "df_dummy_date['dYearsOld'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.date.today()\n",
    "daysdiff = today-df_dummy_date['DOB_of_Driver']\n",
    "components = daysdiff.dt.components #  https://stackoverflow.com/questions/18215317/extracting-days-from-a-numpy-timedelta64-value\n",
    "components.head()\n",
    "years = components.days/365\n",
    "df_dummy_date['DriverYearsOld'] = years\n",
    "df_dummy_date['DriverYearsOld'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_claim['Accident_Date'])  # between 2015/01 -> 2016/12    24months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daysdiff = today-df_dummy_date['Accident_Date']\n",
    "components = daysdiff.dt.components #  https://stackoverflow.com/questions/18215317/extracting-days-from-a-numpy-timedelta64-value\n",
    "months = components.days/30\n",
    "df_dummy_date['Accident_Month_ago'] = months\n",
    "df_dummy_date['Accident_Month_ago'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "df_dummy_date['Acc_DayOfWeek'] = df_dummy_date.apply(lambda row: row['Accident_Date'].weekday(), axis =1)\n",
    "df_dummy_date['Acc_DayOfWeek'][:5]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daysdiff = today-df_dummy_date['Accident_Time']\n",
    "components = daysdiff.dt.components #  https://stackoverflow.com/questions/18215317/extracting-days-from-a-numpy-timedelta64-value\n",
    "hours = components.hours\n",
    "df_dummy_date['Accident_Hour'] = hours\n",
    "df_dummy_date['Accident_Hour'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy_date[date_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_date_cols = ['ibirth', 'dbirth', 'DOB_of_Driver','Accident_Date', 'Accident_Time']\n",
    "df_dummy_date = df_dummy_date.drop (drop_date_cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dummy_date.shape)\n",
    "df_dummy_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy_date.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 convert object (string) to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df[] = pd.to_numeric(df[], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Train, Test, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_dummy_date.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_dummy_date \n",
    "\n",
    "df_train = df[df['Next_Premium']!=100]\n",
    "print(df_train.shape)\n",
    "df_test = df[df['Next_Premium']==100]\n",
    "print(df_test.shape)\n",
    "print(df_train.shape[0]+df_test.shape[0])\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_train['Next_Premium']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.drop(['Next_Premium'], axis=1)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df_test.drop(['Next_Premium'], axis=1)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = df_train\n",
    "test = df_test\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## downsampling for testing:\n",
    "# train = df_train.head(50000) # 1,212,659\n",
    "# y_train = y.head(50000)\n",
    "# ## downsampling for testing:\n",
    "# test=df_test.head(3000)   #776,268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv('train.csv')\n",
    "# test.to_csv('test.csv')\n",
    "# y.to_csv('y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Validation function\n",
    "n_folds = 5\n",
    "\n",
    "def mae_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    mae= np.sqrt(-cross_val_score(model, train.values, y_train.values, scoring=\"neg_mean_absolute_error\", cv = kf))\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb mae: \n",
      " [ 64.59504249  63.44476755  66.81633761  68.8576655   63.34448601]\n",
      "lgb score: 65.4117 (2.1287)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LGBM :\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',n_estimators=200)\n",
    "mae = mae_cv(model_lgb)\n",
    "print(\"lgb mae: \\n\", mae)\n",
    "print(\"lgb score: {:.4f} ({:.4f})\\n\".format(mae.mean(), mae.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-d7dca15e2b2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_lgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_lgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "model_lgb.fit(train, y)\n",
    "y_pred = model_lgb.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3853.44112957,   3762.3679415 ,   3762.3679415 ,   3762.3679415 ,\n",
       "         4241.48189431,   3762.3679415 ,   8908.41066095,  15636.78064565,\n",
       "         8846.21902987,   8649.54298545])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140510, 2)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(776268,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-cfdfa92f01a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_submit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_submit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_testing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_testing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_testing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_submit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_testing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_submit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2329\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2331\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2396\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2397\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2398\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   2566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2567\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2568\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2570\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_sanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m   2877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2878\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2879\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Length of values does not match length of '\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2881\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPeriodIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "df_submit=df_testing\n",
    "df_submit[df_testing.columns[0]]=df_testing[df_testing.columns[0]]\n",
    "df_submit[df_testing.columns[1]]=y_pred\n",
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-65efdf368333>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# XGBoost :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmae_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_xgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Xgboost mae: \\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Xgboost score: {:.4f} ({:.4f})\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-cc5a2536b211>\u001b[0m in \u001b[0;36mmae_cv\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmae_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmae\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"neg_mean_absolute_error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model)\u001b[0m\n\u001b[1;32m    291\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                               verbose_eval=verbose, xgb_model=xgb_model)\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 898\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # XGBoost :\n",
    "# model_xgb = xgb.XGBRegressor(n_estimators=200)\n",
    "# mae = mae_cv(model_xgb)\n",
    "# print(\"Xgboost mae: \\n\", mae)\n",
    "# print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(mae.mean(), mae.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF :\n",
    "model_rf=RandomForestRegressor(n_estimators=20)\n",
    "mae = mae_cv(model_rf)\n",
    "print(\"RandomForest mae: \\n\", mae)\n",
    "print(\"\\nRandomForest score: {:.4f} ({:.4f})\\n\".format(mae.mean(), mae.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
